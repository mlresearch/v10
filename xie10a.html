 <head> 
  <link rel="alternate" type="application/rss+xml" href="http://jmlr.csail.mit.edu/jmlr.xml" title="JMLR RSS"> 
<link rel="stylesheet" type="text/css" href="http://jmlr.csail.mit.edu/style.css"> 
<style>. {font-family:verdana,helvetica,sans-serif}
a {text-decoration:none;color:#3030a0}
</style> 
<style type="text/css"> 
<!-- 
#fixed {
    position: absolute;
    top: 0;
    left: 0;
    width: 8em;
    height: 100%;
}
body > #fixed {
    position: fixed;
}
#content {
    margin-top: 1em;
    margin-left: 10em;
    margin-right: 0.5em;
}
img.jmlr {
    width: 7em;
}
img.rss {
    width: 2em;
}
-->
</style> 
<script LANGUAGE='JavaScript'> 
<!-- function GoAddress(user,machine) {
document.location = 'mailto:' + user + '@' + machine; } 
// -->
</script> 
 
 
<style> 
. {font-family:verdana,helvetica,sans-serif}
a {text-decoration:none;color:#3030a0}
</style> 
</head> 
 <body> 
 <div id="content"> 
<h2>Learning Dissimilarities for Categorical Symbols</h2> 
<p><i><b>Jierui Xie, Boleslaw Szymanski and Mohammed Zaki</b></i>; 
JMLR W&P 10:97-106, 2010.</p> 
<h3>Abstract</h3> 
 
In this paper we learn a dissimilarity measure for categorical data, for effective classification of the data points. Each categorical feature (with values taken from a finite set of symbols) is mapped onto a continuous feature whose values are real numbers. Guided by the classification error based on a nearest neighbor based technique, we repeatedly update the assignment of categorical symbols to real numbers to minimize this error. Intuitively, the algorithm pushes together points with the same class label, while enlarging the distances to points labeled differently. Our experiments show that 1) the learned dissimilarities improve classification accuracy by using the affinities of categorical symbols; 2) they outperform dissimilarities produced by previous data-driven methods; 3) our enhanced nearest neighbor classifier (called LD) based on the new space is competitive compared with classifiers such as decision trees, RBF neural networks, Naive Bayes and support vector machines, on a range of categorical datasets. 
 
</div> 
 <div id="fixed"> 
<br> 
<a align="right" href="http://www.jmlr.org" target=_top><img align="right" class="jmlr" src="http://jmlr.csail.mit.edu/jmlr.jpg" border="0"></a> 
<p><br><br> 
<p align="right"> <A href="http://www.jmlr.org/"> Home Page </A> 
 
<p align="right"> <A href="/papers"> Papers </A> 
 
<p align="right"> <A href="/author-info.html"> Submissions </A> 
 
<p align="right"> <A href="/news.html"> News </A> 
 
<p align="right"> <A href="/scope.html"> Scope </A> 
 
<p align="right"> <A href="/editorial-board.html"> Editorial Board </A> 
 
<p align="right"> <A href="/announcements.html"> Announcements </A> 
 
<p align="right"> <A href="/proceedings"> Proceedings </A> 
 
<p align="right"> <A href="/mloss">Open Source Software</A> 
 
<p align="right"> <A href="/search-jmlr.html"> Search </A> 
 
<a href="index.htm">index</a><p align="right"> <A href="/manudb"> Login </A></p> 
 
<br><br> 
<p align="right"> <A href="http://jmlr.csail.mit.edu/jmlr.xml"> 
<img src="http://jmlr.csail.mit.edu/RSS.gif" class="rss" alt="RSS Feed"> 
</A> 
 
 
 
</div> 
 
</body>