---
title: Increasing Feature Selection Accuracy for L1 Regularized Linear Models
abstract: "L1 (also referred to as the 1-norm or Lasso) penalty based formulations
  have been shown to be e\vective in problem domains when noisy features are present.
  However, the L1 penalty does not give favorable asymptotic properties with respect
  to feature selection, and has been shown to be inconsistent as a feature selection
  estimator; e.g. when noisy features are correlated with the relevant features. This
  can a\vect the estimation of the correct feature set, in certain domains like robotics,
  when both the number of examples and the number of features are large. The weighted
  lasso penalty by (Zou, 2006) has been proposed to rectify this problem of correct
  estimation of the feature set. This paper proposes a novel method for identifying
  problem specific L1 feature weights by utilizing the results from (Zou, 2006) and
  (Rocha et al., 2009) and is applicable to regression and classification algorithms.
  Our method increases the accuracy of L1 penalized algorithms through randomized
  experiments on subsets of the training data as a fast pre-processing step. We show
  experimental and theoretical results supporting the e\x0Ecacy of the proposed method
  on two L1 penalized classification algorithms."
pdf: http://proceedings.mlr.press/v10/jaiantilal10a/jaiantilal10a.pdf
layout: inproceedings
series: Proceedings of Machine Learning Research
id: jaiantilal10a
month: 0
firstpage: 86
lastpage: 96
page: 86-96
sections: 
author:
- given: Abhishek
  family: Jaiantilal
- given: Gregory
  family: Grudic
date: 2010-05-26
address: Hyderabad, India
publisher: PMLR
container-title: Proceedings of the Fourth International Workshop on Feature Selection
  in Data Mining
volume: '10'
genre: inproceedings
issued:
  date-parts:
  - 2010
  - 5
  - 26
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
